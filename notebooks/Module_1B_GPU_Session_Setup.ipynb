{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1B: GPU Session Setup\n",
    "## Run This on the AMD Cloud Droplet Before Modules 6â€“7\n",
    "\n",
    "---\n",
    "\n",
    "This is a **minimal** setup notebook for GPU training sessions. It only installs whatâ€™s needed for PyTorch + ROCm and verifies your GPU.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Youâ€™ve already completed Modules 2â€“5 on your local Mac\n",
    "- Youâ€™ve uploaded `dataset_1M.h5` to this droplet (see Step 0 below)\n",
    "\n",
    "**What this installs:** PyTorch + ROCm, h5py, tqdm\n",
    "\n",
    "**What this does NOT install:** HITRAN/HAPI, matplotlib, seaborn (not needed for training)\n",
    "\n",
    "**Time required:** ~3â€“4 minutes (mostly downloading PyTorch + ROCm)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Verify Dataset Upload\n",
    "\n",
    "Before running this notebook, make sure youâ€™ve uploaded your dataset from your Mac:\n",
    "\n",
    "```bash\n",
    "# From your Mac terminal:\n",
    "scp ~/methane-ml-course/data/datasets/dataset_1M.h5 \\\n",
    "    root@<DROPLET_IP>:/root/methane-ml-course/data/datasets/\n",
    "```\n",
    "\n",
    "Run the cell below to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€ Project paths (GPU droplet) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PROJECT_DIR = Path.home() / 'methane-ml-course'\n",
    "DATA_DIR    = PROJECT_DIR / 'data'\n",
    "DATASET_DIR = DATA_DIR / 'datasets'\n",
    "MODEL_DIR   = PROJECT_DIR / 'models'\n",
    "OUTPUT_DIR  = PROJECT_DIR / 'outputs'\n",
    "\n",
    "# â”€â”€ PyTorch / ROCm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PYTORCH_INDEX_URL = 'https://download.pytorch.org/whl/rocm6.2'\n",
    "\n",
    "# Create dirs\n",
    "for d in [DATA_DIR, DATASET_DIR, MODEL_DIR, OUTPUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check for dataset\n",
    "dataset_path = DATASET_DIR / 'dataset_1M.h5'\n",
    "if dataset_path.exists():\n",
    "    size_gb = dataset_path.stat().st_size / 1e9\n",
    "    print(f\"âœ… Dataset found: {dataset_path} ({size_gb:.2f} GB)\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Dataset NOT found at: {dataset_path}\")\n",
    "    print(f\"    Upload it from your Mac first (see instructions above).\")\n",
    "    print(f\"    You can still proceed with setup, but training will need the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install PyTorch + ROCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: Installing PyTorch + ROCm\")\n",
    "print(\"=\"*60)\n",
    "print(\"This takes ~2-3 minutes (downloading ~4 GB)...\\n\")\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, '-m', 'pip', 'install',\n",
    "    'torch', 'torchvision',\n",
    "    '--index-url', PYTORCH_INDEX_URL,\n",
    "    '--quiet'\n",
    "])\n",
    "print(\"âœ” PyTorch + ROCm\")\n",
    "\n",
    "# Minimal additional deps for training\n",
    "for pkgs, label in [\n",
    "    (['h5py', 'tqdm', 'pyyaml'], 'h5py, tqdm, pyyaml'),\n",
    "]:\n",
    "    subprocess.check_call(\n",
    "        [sys.executable, '-m', 'pip', 'install'] + pkgs + ['--quiet']\n",
    "    )\n",
    "    print(f\"âœ” {label}\")\n",
    "\n",
    "print(\"\\nâœ… All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 2: Verifying GPU Access\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"ROCm available : {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count      : {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name       : {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU memory     : {total_mem:.0f} GB\")\n",
    "    \n",
    "    # Compute tests\n",
    "    print(\"\\nRunning GPU compute tests...\")\n",
    "    x = torch.randn(5000, 5000, device='cuda')\n",
    "    y = torch.matmul(x, x)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"âœ” Matrix multiplication: PASSED\")\n",
    "    \n",
    "    x = torch.randn(100, requires_grad=True, device='cuda')\n",
    "    y = (x ** 2).sum()\n",
    "    y.backward()\n",
    "    print(\"âœ” Gradient computation: PASSED\")\n",
    "    \n",
    "    print(\"\\nâœ… GPU is working correctly!\")\n",
    "else:\n",
    "    print(\"\\nâŒ GPU not detected! Check ROCm installation.\")\n",
    "    print(\"Try running from SSH: rocm-smi\")\n",
    "    print(\"Also check: docker exec -it rocm rocm-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… GPU Session Setup Complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"         GPU SESSION SETUP SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "\n",
    "gpu_ok = torch.cuda.is_available()\n",
    "gpu_status = f\"âœ… {torch.cuda.get_device_name(0)}\" if gpu_ok else \"âŒ Not detected\"\n",
    "\n",
    "dataset_ok = dataset_path.exists()\n",
    "dataset_status = \"âœ… Ready\" if dataset_ok else \"âŒ Not uploaded\"\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Component          â”‚  Status                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  PyTorch + ROCm     â”‚  {torch.__version__:<30} â”‚\n",
    "â”‚  GPU                â”‚  {gpu_status:<30} â”‚\n",
    "â”‚  Dataset            â”‚  {dataset_status:<30} â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "if gpu_ok and dataset_ok:\n",
    "    print(\"ğŸ‰ ALL SYSTEMS GO! Proceed to Module 6 (Build 1D-CNN).\")\n",
    "elif gpu_ok and not dataset_ok:\n",
    "    print(\"âš ï¸  GPU ready, but dataset missing.\")\n",
    "    print(\"    Upload dataset_1M.h5 from your Mac, then re-run Step 0.\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU issues detected. Check ROCm installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## After Training: Download Your Model\n",
    "\n",
    "Once Module 7 is complete and you have `best_model.pt`, download it to your Mac for local inference:\n",
    "\n",
    "```bash\n",
    "# From your Mac terminal:\n",
    "scp root@<DROPLET_IP>:/root/methane-ml-course/models/best_model.pt \\\n",
    "    ~/methane-ml-course/models/\n",
    "```\n",
    "\n",
    "Then you can run Modules 8â€“9 locally on your Mac â€” no GPU needed!\n",
    "\n",
    "**Donâ€™t forget** to snapshot and destroy the droplet when done to stop billing.\n",
    "\n",
    "---\n",
    "\n",
    "**Module 1B Complete!** Proceed to Module 6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
