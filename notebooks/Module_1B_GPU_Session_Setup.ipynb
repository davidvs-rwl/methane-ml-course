{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Module 1B: GPU Session Setup\n## Run This on the AMD Cloud Droplet Before Modules 6\u20137\n\n---\n\nThis is a **minimal** setup notebook for GPU training sessions. It only installs what\u2019s needed for PyTorch + ROCm and verifies your GPU.\n\n**Prerequisites:**\n- You\u2019ve already completed Modules 2\u20135 on your local Mac\n- You\u2019ve uploaded `dataset_1M.h5` to this droplet (see Step 0 below)\n\n**What this installs:** PyTorch + ROCm, h5py, tqdm\n\n**What this does NOT install:** HITRAN/HAPI, matplotlib, seaborn (not needed for training)\n\n**Time required:** ~3\u20134 minutes (mostly downloading PyTorch + ROCm)\n\n---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 0: Verify Dataset Upload\n\nBefore running this notebook, make sure you\u2019ve uploaded your dataset from your Mac:\n\n```bash\n# From your Mac terminal:\nscp ~/methane-ml-course/data/datasets/dataset_1M.h5 \\\n    root@<DROPLET_IP>:/root/methane-ml-course/data/datasets/\n```\n\nRun the cell below to check:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pathlib import Path\n\n# \u2500\u2500 Project paths (GPU droplet) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_DIR = Path.home() / 'methane-ml-course'\nDATA_DIR    = PROJECT_DIR / 'data'\nDATASET_DIR = DATA_DIR / 'datasets'\nMODEL_DIR   = PROJECT_DIR / 'models'\nOUTPUT_DIR  = PROJECT_DIR / 'outputs'\n\n# \u2500\u2500 PyTorch / ROCm \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPYTORCH_INDEX_URL = 'https://download.pytorch.org/whl/rocm6.2'\n\n# Create dirs\nfor d in [DATA_DIR, DATASET_DIR, MODEL_DIR, OUTPUT_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\n# Check for dataset\ndataset_path = DATASET_DIR / 'dataset_1M.h5'\nif dataset_path.exists():\n    size_gb = dataset_path.stat().st_size / 1e9\n    print(f\"\u2705 Dataset found: {dataset_path} ({size_gb:.2f} GB)\")\nelse:\n    print(f\"\u26a0\ufe0f  Dataset NOT found at: {dataset_path}\")\n    print(f\"    Upload it from your Mac first (see instructions above).\")\n    print(f\"    You can still proceed with setup, but training will need the file.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Install PyTorch + ROCm",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import subprocess, sys\n\nprint(\"=\"*60)\nprint(\"STEP 1: Installing PyTorch + ROCm\")\nprint(\"=\"*60)\nprint(\"This takes ~2-3 minutes (downloading ~4 GB)...\\n\")\n\nsubprocess.check_call([\n    sys.executable, '-m', 'pip', 'install',\n    'torch', 'torchvision',\n    '--index-url', PYTORCH_INDEX_URL,\n    '--quiet'\n])\nprint(\"\u2714 PyTorch + ROCm\")\n\n# Minimal additional deps for training\nfor pkgs, label in [\n    (['h5py', 'tqdm', 'pyyaml'], 'h5py, tqdm, pyyaml'),\n]:\n    subprocess.check_call(\n        [sys.executable, '-m', 'pip', 'install'] + pkgs + ['--quiet']\n    )\n    print(f\"\u2714 {label}\")\n\nprint(\"\\n\u2705 All packages installed!\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Verify GPU Access",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"=\"*60)\nprint(\"STEP 2: Verifying GPU Access\")\nprint(\"=\"*60)\n\nimport torch\n\nprint(f\"\\nPyTorch version: {torch.__version__}\")\nprint(f\"ROCm available : {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU count      : {torch.cuda.device_count()}\")\n    print(f\"GPU name       : {torch.cuda.get_device_name(0)}\")\n    \n    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"GPU memory     : {total_mem:.0f} GB\")\n    \n    # Compute tests\n    print(\"\\nRunning GPU compute tests...\")\n    x = torch.randn(5000, 5000, device='cuda')\n    y = torch.matmul(x, x)\n    torch.cuda.synchronize()\n    print(\"\u2714 Matrix multiplication: PASSED\")\n    \n    x = torch.randn(100, requires_grad=True, device='cuda')\n    y = (x ** 2).sum()\n    y.backward()\n    print(\"\u2714 Gradient computation: PASSED\")\n    \n    print(\"\\n\u2705 GPU is working correctly!\")\nelse:\n    print(\"\\n\u274c GPU not detected! Check ROCm installation.\")\n    print(\"Try running from SSH: rocm-smi\")\n    print(\"Also check: docker exec -it rocm rocm-smi\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n## \u2705 GPU Session Setup Complete!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"\\n\" + \"=\"*60)\nprint(\"         GPU SESSION SETUP SUMMARY\")\nprint(\"=\"*60)\n\nimport torch\n\ngpu_ok = torch.cuda.is_available()\ngpu_status = f\"\u2705 {torch.cuda.get_device_name(0)}\" if gpu_ok else \"\u274c Not detected\"\n\ndataset_ok = dataset_path.exists()\ndataset_status = \"\u2705 Ready\" if dataset_ok else \"\u274c Not uploaded\"\n\nprint(f\"\"\"\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Component          \u2502  Status                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PyTorch + ROCm     \u2502  {torch.__version__:<30} \u2502\n\u2502  GPU                \u2502  {gpu_status:<30} \u2502\n\u2502  Dataset            \u2502  {dataset_status:<30} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\"\"\")\n\nif gpu_ok and dataset_ok:\n    print(\"\ud83c\udf89 ALL SYSTEMS GO! Proceed to Module 6 (Build 1D-CNN).\")\nelif gpu_ok and not dataset_ok:\n    print(\"\u26a0\ufe0f  GPU ready, but dataset missing.\")\n    print(\"    Upload dataset_1M.h5 from your Mac, then re-run Step 0.\")\nelse:\n    print(\"\u26a0\ufe0f  GPU issues detected. Check ROCm installation.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n## After Training: Download Your Model\n\nOnce Module 7 is complete and you have `best_model.pt`, download it to your Mac for local inference:\n\n```bash\n# From your Mac terminal:\nscp root@<DROPLET_IP>:/root/methane-ml-course/models/best_model.pt \\\n    ~/methane-ml-course/models/\n```\n\nThen you can run Modules 8\u20139 locally on your Mac \u2014 no GPU needed!\n\n**Don\u2019t forget** to snapshot and destroy the droplet when done to stop billing.\n\n---\n\n**Module 1B Complete!** Proceed to Module 6.",
      "metadata": {}
    }
  ]
}