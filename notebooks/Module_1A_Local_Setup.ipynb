{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Module 1A: Local Environment Setup\n## Run This Once on Your Mac (Then Re-run Only If Needed)\n\n---\n\nThis notebook sets up your **local MacBook Pro** for Modules 2\u20135, 8, and 9. These modules involve spectroscopic simulation, dataset generation, and inference \u2014 all CPU-bound work that doesn\u2019t need a GPU.\n\n**What this installs:**\n- HAPI (HITRAN API) for spectroscopic data\n- NumPy, Matplotlib, Seaborn for computation and plotting\n- h5py for HDF5 dataset files\n- PyTorch (CPU-only) for model architecture prototyping and local inference\n\n**What this does NOT install:**\n- ROCm or GPU drivers (that\u2019s Module 1B, on the cloud droplet)\n- Heavy vision packages (ultralytics, albumentations, opencv)\n\n**Time required:** ~2\u20133 minutes\n\n---\n\n### Hybrid Workflow Overview\n\n```\nYour Mac (Modules 1A, 2\u20135, 8\u20139)       AMD GPU Droplet (Modules 1B, 6\u20137)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Physics, Simulation, Data Gen  \u2502   \u2502  CNN Training (GPU)        \u2502\n\u2502  Inference, Export              \u2502   \u2502  GPU Verification           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        dataset_1M.h5  \u2500\u2500 scp \u2500\u2500\u2500\u2500\u2500\u2192\n        best_model.pt  \u2500\u2500 scp \u2500\u2500\u2500\u2500\u2500\u2190\n```\n\n---",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Course Configuration\n\nAll course-wide parameters are defined here. Every subsequent cell and module references these variables.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pathlib import Path\nimport platform\n\n# \u2500\u2500 Project paths (portable \u2014 works on Mac and Linux) \u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_DIR = Path.home() / 'methane-ml-course'\nDATA_DIR    = PROJECT_DIR / 'data'\nHITRAN_DIR  = DATA_DIR / 'hitran'\nSPECTRA_DIR = DATA_DIR / 'spectra'\nDATASET_DIR = DATA_DIR / 'datasets'\nMODEL_DIR   = PROJECT_DIR / 'models'\nOUTPUT_DIR  = PROJECT_DIR / 'outputs'\n\n# \u2500\u2500 HITRAN / spectroscopy parameters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nMOLECULE_ID  = 6          # CH4\nISOTOPE_ID   = 1          # Main isotopologue (12CH4)\nNU_MIN       = 4383.0     # cm\u207b\u00b9  \u2014 start of wavenumber range\nNU_MAX       = 4386.0     # cm\u207b\u00b9  \u2014 end of wavenumber range\nTABLE_NAME   = 'CH4_4383_4386'\n\n# \u2500\u2500 Default simulation environment \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nDEFAULT_TEMP     = 296.0  # K   (HITRAN reference temperature)\nDEFAULT_PRESSURE = 1.0    # atm\nMOLE_FRACTION    = 0.01   # 1% CH4 (for absorption coefficient calc)\nWAVENUMBER_STEP  = 0.001  # cm\u207b\u00b9  \u2014 spectral resolution\n\n# \u2500\u2500 Device selection (CPU for local, GPU when available) \u2500\u2500\nDEVICE = 'cpu'  # Modules 2-5 don't need a GPU\n\nprint(f\"System          : {platform.system()} {platform.machine()}\")\nprint(f\"Project dir     : {PROJECT_DIR}\")\nprint(f\"HITRAN dir      : {HITRAN_DIR}\")\nprint(f\"Table name      : {TABLE_NAME}\")\nprint(f\"Wavenumber range: {NU_MIN} \u2013 {NU_MAX} cm\u207b\u00b9\")\nprint(f\"Compute device  : {DEVICE}\")\nprint(\"\\n\u2705 Configuration loaded.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Install Course Packages\n\nWe install PyTorch CPU-only (much smaller download than ROCm) plus the science stack.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import subprocess, sys\n\nprint(\"=\"*60)\nprint(\"STEP 1: Installing Packages\")\nprint(\"=\"*60)\nprint()\n\n# Group 1: PyTorch CPU-only (~200 MB vs ~4 GB for ROCm)\nprint(\"Installing PyTorch (CPU-only)...\")\nsubprocess.check_call([\n    sys.executable, '-m', 'pip', 'install',\n    'torch', 'torchvision',\n    '--index-url', 'https://download.pytorch.org/whl/cpu',\n    '--quiet'\n])\nprint(\"\u2714 PyTorch (CPU)\")\n\n# Group 2: Science stack\nfor pkgs, label in [\n    (['hitran-api'],                           'hitran-api'),\n    (['numpy', 'matplotlib', 'seaborn'],       'numpy, matplotlib, seaborn'),\n    (['h5py', 'tqdm', 'pyyaml'],               'h5py, tqdm, pyyaml'),\n]:\n    subprocess.check_call(\n        [sys.executable, '-m', 'pip', 'install'] + pkgs + ['--quiet']\n    )\n    print(f\"\u2714 {label}\")\n\nprint(\"\\n\u2705 All packages installed!\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Set Up Project Directories",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"=\"*60)\nprint(\"STEP 2: Setting Up Project Directories\")\nprint(\"=\"*60)\n\nfor d in [DATA_DIR, HITRAN_DIR, SPECTRA_DIR, DATASET_DIR, MODEL_DIR, OUTPUT_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n    print(f\"\u2714 {d}\")\n\nprint(\"\\n\u2705 Directories created!\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Set Up HITRAN Database\n\nDownload CH\u2084 spectroscopic data for our wavenumber range (4383\u20134386 cm\u207b\u00b9).\n\nThis downloads from the HITRAN server on first run, then uses the cached local copy.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"=\"*60)\nprint(\"STEP 3: Setting Up HITRAN Database\")\nprint(\"=\"*60)\n\nimport hapi\n\nhapi.db_begin(str(HITRAN_DIR))\nprint(f\"HITRAN data directory: {HITRAN_DIR}\")\n\nprint(f\"\\nFetching CH\u2084 data from HITRAN...\")\nprint(f\"  Molecule: CH\u2084 (ID={MOLECULE_ID})\")\nprint(f\"  Isotope: \u00b9\u00b2CH\u2084 (ID={ISOTOPE_ID})\")\nprint(f\"  Wavenumber range: {NU_MIN} \u2013 {NU_MAX} cm\u207b\u00b9\")\n\ntry:\n    hapi.fetch(\n        TableName=TABLE_NAME,\n        M=MOLECULE_ID,\n        I=ISOTOPE_ID,\n        numin=NU_MIN,\n        numax=NU_MAX\n    )\n    print(\"\\n\u2714 Data fetched from HITRAN server\")\nexcept Exception as e:\n    print(f\"\\n\u2714 Using cached data (or: {e})\")\n\n# Verify\ntry:\n    nu_lines = hapi.getColumn(TABLE_NAME, 'nu')\n    sw_lines = hapi.getColumn(TABLE_NAME, 'sw')\n    print(f\"\\nSpectral lines found: {len(nu_lines)}\")\n    for i, (nu, sw) in enumerate(zip(nu_lines[:5], sw_lines[:5])):\n        print(f\"  Line {i+1}: \u03bd = {nu:.4f} cm\u207b\u00b9, Intensity = {sw:.2e}\")\n    if len(nu_lines) > 5:\n        print(f\"  ... and {len(nu_lines)-5} more lines\")\n    print(\"\\n\u2705 HITRAN database ready!\")\nexcept Exception as e:\n    print(f\"\\n\u26a0\ufe0f Could not verify HITRAN data: {e}\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Verify PyTorch (CPU)\n\nWe confirm PyTorch works for local model prototyping and inference. GPU verification happens in Module 1B on the cloud droplet.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"=\"*60)\nprint(\"STEP 4: Verifying PyTorch (CPU)\")\nprint(\"=\"*60)\n\nimport torch\n\nprint(f\"\\nPyTorch version : {torch.__version__}\")\nprint(f\"GPU available   : {torch.cuda.is_available()} (expected: False on Mac)\")\nprint(f\"MPS available   : {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else 'N/A'}\")\nprint(f\"Device          : {DEVICE}\")\n\n# Quick compute test on CPU\nprint(\"\\nRunning CPU compute test...\")\nx = torch.randn(2000, 2000)\ny = torch.matmul(x, x)\nprint(\"\u2714 Matrix multiplication: PASSED\")\n\nx = torch.randn(100, requires_grad=True)\ny = (x ** 2).sum()\ny.backward()\nprint(\"\u2714 Gradient computation: PASSED\")\n\nprint(\"\\n\u2705 PyTorch (CPU) is working correctly!\")\nprint(\"\\nNote: For GPU training, you'll use Module 1B on the AMD cloud droplet.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 5: Verify All Packages",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"=\"*60)\nprint(\"STEP 5: Verifying All Packages\")\nprint(\"=\"*60)\n\npackages = {\n    'torch': 'torch',\n    'torchvision': 'torchvision',\n    'numpy': 'numpy',\n    'matplotlib': 'matplotlib',\n    'seaborn': 'seaborn',\n    'hapi': 'hapi',\n    'h5py': 'h5py',\n    'tqdm': 'tqdm',\n    'yaml': 'yaml',\n}\n\nall_ok = True\nprint(\"\\nPackage Status:\")\nprint(\"-\" * 40)\n\nfor name, module in packages.items():\n    try:\n        mod = __import__(module)\n        version = getattr(mod, '__version__', 'installed')\n        print(f\"\u2714 {name}: {version}\")\n    except ImportError:\n        print(f\"\u2717 {name}: NOT FOUND\")\n        all_ok = False\n\nif all_ok:\n    print(\"\\n\u2705 All packages verified!\")\nelse:\n    print(\"\\n\u26a0\ufe0f Some packages missing. Re-run Step 1.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n## \u2705 Local Setup Complete!\n\nRun the cell below to confirm everything is ready.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"\\n\" + \"=\"*60)\nprint(\"         LOCAL SESSION SETUP SUMMARY\")\nprint(\"=\"*60)\n\nimport torch\n\n# Check PyTorch\ntorch_ok = True\ntorch_status = f\"\u2705 {torch.__version__} (CPU)\"\n\n# Check HITRAN\nhitran_header = HITRAN_DIR / f\"{TABLE_NAME}.header\"\nhitran_ok = hitran_header.exists()\nhitran_status = \"\u2705 Ready\" if hitran_ok else \"\u274c Not found\"\n\n# Check directories\ndirs_ok = all(d.exists() for d in [DATA_DIR, HITRAN_DIR, MODEL_DIR])\ndirs_status = \"\u2705 Created\" if dirs_ok else \"\u274c Missing\"\n\nprint(f\"\"\"\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Component          \u2502  Status                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PyTorch            \u2502  {torch_status:<30} \u2502\n\u2502  HITRAN Database    \u2502  {hitran_status:<30} \u2502\n\u2502  Directories        \u2502  {dirs_status:<30} \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\"\"\")\n\nif torch_ok and hitran_ok and dirs_ok:\n    print(\"\ud83c\udf89 LOCAL SETUP COMPLETE! You're ready for Modules 2\u20135.\")\n    print(\"\\nNext steps:\")\n    print(\"  1. Open Module_02_Physics_Background.ipynb\")\n    print(\"  2. Or open Module_03_HITRAN_Simulation.ipynb\")\n    print(\"\\n  When you're ready for GPU training (Modules 6\u20137):\")\n    print(\"  3. Upload dataset_1M.h5 to the AMD droplet\")\n    print(\"  4. Run Module_1B_GPU_Session_Setup.ipynb on the droplet\")\nelse:\n    print(\"\u26a0\ufe0f  Some issues detected. Please review the steps above.\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n## Quick Reference: HITRAN Setup for Other Notebooks\n\nAfter running this setup, other local notebooks can use HITRAN like this:\n\n```python\nimport hapi\nfrom pathlib import Path\n\n# Portable path \u2014 works on Mac and Linux\nPROJECT_DIR = Path.home() / 'methane-ml-course'\nHITRAN_DIR  = PROJECT_DIR / 'data' / 'hitran'\nhapi.db_begin(str(HITRAN_DIR))\n\n# Use the pre-fetched CH4 data\nTABLE_NAME = 'CH4_4383_4386'\n\n# Generate spectrum\nnu, coef = hapi.absorptionCoefficient_Voigt(\n    SourceTables=TABLE_NAME,\n    Components=[(6, 1, 0.01)],  # (molecule_id, isotope_id, mole_fraction)\n    Environment={'T': 296, 'p': 1.0},\n    WavenumberRange=[4383, 4386],\n    WavenumberStep=0.001\n)\n```\n\n---\n\n## Transferring Data to/from the GPU Droplet\n\nWhen you're ready for Modules 6\u20137, transfer your generated dataset:\n\n```bash\n# Upload dataset to GPU droplet\nscp ~/methane-ml-course/data/datasets/dataset_1M.h5 \\\n    root@<DROPLET_IP>:/root/methane-ml-course/data/datasets/\n\n# Download trained model back to Mac\nscp root@<DROPLET_IP>:/root/methane-ml-course/models/best_model.pt \\\n    ~/methane-ml-course/models/\n```\n\nOr with Tailscale (if configured):\n```bash\nscp ~/methane-ml-course/data/datasets/dataset_1M.h5 \\\n    root@<TAILSCALE_HOSTNAME>:/root/methane-ml-course/data/datasets/\n```\n\n---\n\n**Module 1A Complete!** Proceed to Module 2 for physics background, or Module 3 to start simulating spectra.",
      "metadata": {}
    }
  ]
}